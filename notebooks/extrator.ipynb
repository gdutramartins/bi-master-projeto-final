{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extrator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extrator Clipping\n",
        "Objetivo: A planilha informada ao BNDES com os artigos de imprensa continha somente o link da publicação, foi necessário navegar pelos links e baixar conteúdo da postagem."
      ],
      "metadata": {
        "id": "XEWyR3UqZuY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update \n",
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "id": "imPL8uYXuhKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c778533e-f9b9-4f49-c36b-0a99c8a3c270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,866 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,047 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,013 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,298 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Fetched 12.4 MB in 5s (2,450 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 9s (9,714 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Yx4SsVviVx",
        "outputId": "7fb4b6c1-b5e5-4190-e26d-053ddf4b5feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 40.0 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 40.6 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3zkvZ3vWteA",
        "outputId": "0ec33ab8-4efd-4b3d-91ca-8e90ff6cd2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Boqzhhezuqaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5783ab-8c20-4a1b-f0d0-45ee3e89a6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from requests.models import Response\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import trange\n",
        "import time\n",
        "import os\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Union\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Tag\n",
        "import unidecode\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.core.series import Series\n",
        "import json\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sulpu8ddRYeM",
        "outputId": "ea9cc70a-5c04-41a3-bc7d-da8ba43b34a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--start-maximized')\n",
        "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36')\n",
        "chrome_options.add_argument('--ignore-certificate-errors')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options, service_args=['--verbose', '--log-path=/tmp/chromedriver.log'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilGSET1oDKIJ",
        "outputId": "23655114-393a-47fc-82d1-2f1baec9f3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVE_PATH:str = '/content/drive/MyDrive'\n",
        "DATASET_ROOT_PATH: str = os.path.join(GDRIVE_PATH, 'dataset', 'projeto-final')\n",
        "DATASET_IMPRENSA: str = os.path.join(DATASET_ROOT_PATH, 'imprensa', 'original')\n",
        "DATASET_MENCOES: str = os.path.join(DATASET_ROOT_PATH, 'mencoes')\n",
        "ARQUIVOS_IMPRENSA_PROCESSAMENTO_SIMPLES: List[str] = ['2020-06-Imprensa.xlsx', '2020-07-Imprensa.xlsx', '2020-08-Imprensa.xlsx', '2020-09-Imprensa.xlsx', \n",
        "                                                      #'2020-10-Imprensa.xlsx', '2020-11-Imprensa.xlsx', \n",
        "                                                      #'2020-12-Imprensa.xlsx'\n",
        "                                                      ]\n",
        "ARQUIVO_IMPRENSA_PROCESSAMENTO_CONSOLIDADO: str = '2021-2022-Imprensa_Consolidada.xlsx'"
      ],
      "metadata": {
        "id": "6uZu1BztQoFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def carrega_arquivos_imprensa_simples() -> None:\n",
        "    vet_artigos: np.ndarray\n",
        "\n",
        "    for arq in ARQUIVOS_IMPRENSA_PROCESSAMENTO_SIMPLES:\n",
        "        df =  pd.read_excel(os.path.join(DATASET_IMPRENSA, arq))\n",
        "        df['texto_artigo'] = pd.Series(dtype='str')\n",
        "        cont_linha: int = 0\n",
        "        vet_artigos = df[['ID', 'Data','Link para o sistema']].to_numpy()\n",
        "        \n",
        "        for row in tqdm(vet_artigos, desc=f'Carregando {arq}'):\n",
        "            try:\n",
        "                wd.get(row[2])\n",
        "                time.sleep(5)\n",
        "                element_present = EC.presence_of_element_located((By.CSS_SELECTOR, '#nNoticia p'))\n",
        "                WebDriverWait(wd, 15).until(element_present)\n",
        "\n",
        "                soup = BeautifulSoup(wd.page_source, 'lxml')\n",
        "                tag_conteudo: Tag = soup.find(id=\"nNoticia\")\n",
        "                conteudo_artigo: str = ''\n",
        "                for tag_paragrafo in tag_conteudo.find_all('p'):        \n",
        "                    if tag_paragrafo.contents and len(tag_paragrafo.contents) > 0:\n",
        "                        conteudo_paragrafo: str = \" \".join(str(item) for item in tag_paragrafo.contents).strip()\n",
        "                        conteudo_paragrafo = unidecode.unidecode(conteudo_paragrafo)\n",
        "                        conteudo_artigo += re.sub(\"<[^>]*>\", \"\", conteudo_paragrafo)\n",
        "                \n",
        "                df.iloc[cont_linha, -1] = conteudo_artigo\n",
        "            except Exception as e:\n",
        "                print(f'Falha no carregamento da página {row[2]} ', e, '\\n')\n",
        "                df.iloc[cont_linha, -1] = 'CONTEUDO_INDISPONIVEL'\n",
        "            finally:\n",
        "                cont_linha += 1\n",
        "\n",
        "        df.to_csv(arq.replace(\".xlsx\",\".csv\"), sep=\"|\")\n",
        "                \n"
      ],
      "metadata": {
        "id": "19ebMzGUUJR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carrega_arquivos_imprensa_simples()"
      ],
      "metadata": {
        "id": "tN4vgXEkUJ-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6c3a99-112c-41fc-886b-328681862977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Carregando 2020-06-Imprensa.xlsx: 100%|██████████| 319/319 [43:32<00:00,  8.19s/it]\n",
            "Carregando 2020-07-Imprensa.xlsx: 100%|██████████| 324/324 [44:10<00:00,  8.18s/it]\n",
            "Carregando 2020-08-Imprensa.xlsx: 100%|██████████| 286/286 [39:45<00:00,  8.34s/it]\n",
            "Carregando 2020-09-Imprensa.xlsx: 100%|██████████| 210/210 [28:46<00:00,  8.22s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def carrega_arquivo_imprensa_consolidado() -> None:\n",
        "    vet_artigos: np.ndarray\n",
        "    tam_lote: int = 20\n",
        "\n",
        "    df =  pd.read_excel(os.path.join(DATASET_IMPRENSA,  ARQUIVO_IMPRENSA_PROCESSAMENTO_CONSOLIDADO))\n",
        "    df['Data da publicação'] = df['Data da publicação'].str.extract(r\"(\\d\\d/\\d\\d/[\\d]*)\")\n",
        "    df['texto_artigo'] = pd.Series(dtype='str')\n",
        "    cont_linha: int = 0\n",
        "    vet_artigos = df[['Matéria', 'Data da publicação','Link web - Texto']].to_numpy()\n",
        "    #vet_artigos = vet_artigos[0:7]\n",
        "    \n",
        "    for row in tqdm(vet_artigos, desc=f'Carregando Impensa Consolidado'):\n",
        "        try:\n",
        "            wd.get(row[2])\n",
        "            time.sleep(5)\n",
        "            element_present = EC.presence_of_element_located((By.CSS_SELECTOR, '#nNoticia p'))\n",
        "            WebDriverWait(wd, 15).until(element_present)\n",
        "\n",
        "            soup = BeautifulSoup(wd.page_source, 'lxml')\n",
        "            tag_conteudo: Tag = soup.find(id=\"nNoticia\")\n",
        "            conteudo_artigo: str = ''\n",
        "            for tag_paragrafo in tag_conteudo.find_all('p'):        \n",
        "                if tag_paragrafo.contents and len(tag_paragrafo.contents) > 0:\n",
        "                    conteudo_paragrafo: str = \" \".join(str(item) for item in tag_paragrafo.contents).strip()\n",
        "                    conteudo_paragrafo = unidecode.unidecode(conteudo_paragrafo)\n",
        "                    conteudo_artigo += re.sub(\"<[^>]*>\", \"\", conteudo_paragrafo)\n",
        "            \n",
        "            df.iloc[cont_linha, -1] = conteudo_artigo\n",
        "        except Exception as e:\n",
        "            print(f'Falha no carregamento da página {row[2]} - {str(e)} \\n')\n",
        "            df.iloc[cont_linha, -1] = 'CONTEUDO_INDISPONIVEL'\n",
        "        finally:\n",
        "            cont_linha += 1\n",
        "            if cont_linha % tam_lote == 0:\n",
        "                df.to_csv(\"consolidado.csv\", sep=\"|\")            \n",
        "\n",
        "    df.to_csv(\"consolidado.csv\", sep=\"|\")"
      ],
      "metadata": {
        "id": "hHWeq6vAZL4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carrega_arquivo_imprensa_consolidado()"
      ],
      "metadata": {
        "id": "DmVU12qq1d7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgRAlXYh2bry"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}